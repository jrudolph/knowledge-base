{"docs":[{"location":"/paradox.json","text":"","title":""},{"location":"/index.html","text":"","title":"@jrudolphs Knowledge Base"},{"location":"/index.html#jrudolphs-knowledge-base","text":"","title":"@jrudolph’s Knowledge Base"},{"location":"/index.html#whats-this-","text":"A collection of computing resources and personal learnings collected by me. It’s mostly a semi-structured way for me to keep links and insights.\nIt’s published and public mostly because that’s easiest for my own needs but also because sometimes people find similar things useful.\nScala JVM Hosting Machine Learning Documentation Tools Various","title":"What’s This?"},{"location":"/scala/index.html","text":"","title":"Scala"},{"location":"/scala/index.html#scala","text":"SBT Tricks Discover Scala Code Scala Compilation Speed Various","title":"Scala"},{"location":"/scala/sbt.html","text":"","title":"SBT Tricks"},{"location":"/scala/sbt.html#sbt-tricks","text":"","title":"SBT Tricks"},{"location":"/scala/sbt.html#dont-pusblish-docs-on-publishlocal","text":"Often building docs is the slowest part of a publishLocal so it’s recommended to turn it off if not needed.\nsbt/sbt#3537 recommends to set\nset publishArtifact in (Compile, packageDoc) in ThisBuild := false\ntemporarily to avoid building docs for publishing.","title":"Don’t pusblish docs on publishLocal"},{"location":"/scala/code-browsing.html","text":"","title":"Discover Scala Code"},{"location":"/scala/code-browsing.html#discover-scala-code","text":"Sometimes it’s useful to be able to browse existing open source Scala code online to find examples or just see how your dependencies work. Like for any more full-fledged IDE, the most important basic functionality is “Go to definition” that cross-links source files (in the best case across libraries). In times when you don’t have an IDE at hand or you need to browse third party dependencies for which you don’t have the tooling set up, it can be nice to be able to discover Scala directly in the browser.\nNice-to-have functionality would be:\n“Go To Definition” (in single files, across files, across library boundaries) Global “Find all usages” - reverse of “Go To Definition” to find where symbols are used Global Search for symbols / documentation Custom linking setup (for a resolved dependency graph with possibly pulled up dependencies) Code statistics - similar content as was provided in my 2014 Scala In Numbers talk\nThe following are current best options:","title":"Discover Scala Code"},{"location":"/scala/code-browsing.html#metadoc","text":"Homepage Demo\nThe newest instance of such a tool. Uses the scalameta semantic API to render code and provide cross-linking. The demo seems to contain at least the Scala library contents. No live version that allows to browse arbitrary libraries.","title":"Metadoc"},{"location":"/scala/code-browsing.html#sxr-scala-x-ray","text":"Homepage Demo\nAn old project of Mark Harrah which could be used to generate browsable source code which seemed to work well enough but is out of maintenance for a long time.","title":"sxr - Scala X-Ray"},{"location":"/scala/code-browsing.html#scaladex","text":"Homepage\nAn index of Scala libraries. Has a search engine for content, tags, and versions but no way to actually browse or search into the source code (aside from looking it up at Github).","title":"scaladex"},{"location":"/scala/code-browsing.html#other-tools","text":"sourcegraph.com - seems to support searching for symbols and works well enough for that. Cross linking is supported in general but does not seem to work nicely for Scala. searchcode.com - seems to work but unclear coverage elixir.bootlin.com - seems to be the successor of LXR the Linux source code browsing tool. grepcode.com - one popular search engine, unfortunately extinct by now","title":"Other tools"},{"location":"/scala/compilation-speed.html","text":"","title":"Scala Compilation Speed"},{"location":"/scala/compilation-speed.html#scala-compilation-speed","text":"Scala has been somewhat notorious for long compile times. This has improved a lot over the years. Compared to other high-level language compilers, it’s probably not too bad (though the usual comparison with Java hurts).\nScala has a working incremental compiler, so when used from sbt (or other build systems), recompilation is not a big issue in most cases.","title":"Scala Compilation Speed"},{"location":"/scala/compilation-speed.html#potential-culprits-for-slow-compile-times","text":"In user code (in no particular order):\nHeavy use of implicits Type inference (adding explicit types to public members can help a lot) Macros (can disturb incremental compilation when macros are defined in an internal dependency and that changes) Big Modules (if you avoid circular dependencies between files you can often restructure code into more modules to help with parallelism) Mixed Mode projects containing Java and Scala files (at least that’s what I observed in akka-http that sbt cannot infer well enough what to recompile and incremental compilation is slower than a full recompile)\nIn scalac’s compiler architecture:\nMostly single-threaded execution (outline compilation might be a remedy in the future)","title":"Potential culprits for slow compile times"},{"location":"/scala/compilation-speed.html#other-scala-compilers-with-a-focus-on-speed","text":"triplequote hydra - a commercial parallel Scala compiler implementation twitter rsc - “Reasonable Scala compiler (also known as Rsc) is an experimental Scala compiler focused on compilation speed.” gkossakowski’s kentucky mule - “an exploration of an alternative architecture for Scala compiler design (specifically typechecker) with a focus on speed” dotty - The next-generation compiler for Scala 3 - a simpler type-system and a new compiler architecture may or may not bring performance improvements (haven’t seen benchmarks)","title":"Other Scala compilers with a focus on speed"},{"location":"/scala/compilation-speed.html#tools","text":"scalac-profiling - “aims at providing the tools to understand and profile your Scala projects” scalafix ExplicitResultTypes refactoring - explicit result type will help compilation speed already now but it’s also mandatory for outline compilation (when that is available) bloop - “One toolchain, one build server, one developer experience”","title":"Tools"},{"location":"/scala/various.html","text":"","title":"Various"},{"location":"/scala/various.html#various","text":"","title":"Various"},{"location":"/scala/various.html#blogs","text":"2018-08-23: Are Scala Futures the Past Shortcoming of Scala Futures and recent alternatives from scalaz-zio, cats, and monix","title":"Blogs"},{"location":"/jvm/index.html","text":"","title":"JVM"},{"location":"/jvm/index.html#jvm","text":"Graal VM Project Loom","title":"JVM"},{"location":"/jvm/graal.html","text":"","title":"Graal VM"},{"location":"/jvm/graal.html#graal-vm","text":"Homepage | Documentation | Github","title":"Graal VM"},{"location":"/jvm/graal.html#native-image","text":"","title":"Native Image"},{"location":"/jvm/graal.html#scala-2-13-x-support","text":"See scala/bug#11634, you will need a substitution for scala.runtime.Statics:\nimport com.oracle.svm.core.annotate.Substitute;\nimport com.oracle.svm.core.annotate.TargetClass;\n\n@TargetClass(className = \"scala.runtime.Statics\")\nfinal class Target_scala_runtime_Statics {\n\n    @Substitute\n    public static void releaseFence() {\n        UnsafeUtils.UNSAFE.storeFence();\n    }\n}\nimport java.lang.reflect.Field;\n\nclass UnsafeUtils {\n    static final sun.misc.Unsafe UNSAFE;\n\n    static {\n        try {\n            Field field = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\");\n            field.setAccessible(true);\n            UNSAFE = (sun.misc.Unsafe) field.get(null);\n        } catch (Throwable ex) {\n            throw new ExceptionInInitializerError(ex);\n        }\n    }\n}","title":"Scala 2.13.x support"},{"location":"/jvm/graal.html#size-of-generated-image","text":"Currently not quite optimized it seems. See oracle/graal#287 for ongoing discussion about that.","title":"Size of generated image"},{"location":"/jvm/graal.html#generating-heap-dumps-for-substrate-vm-at-runtime","text":"Warning Currently not possible for CE!\nDocumentation for EE","title":"Generating heap dumps for substrate VM at runtime"},{"location":"/jvm/graal.html#print-heap-histogram-from-inside-binary","text":"Similar to what jmap -histo would do on openjdk but from inside the process. Would probably make sense to trigger GC right before that if you are only interested in live objects.\n(as of CE 20.1.0)\nimport com.oracle.svm.core.heap.ClassHistogramVisitor;\nimport com.oracle.svm.core.heap.Heap;\nimport com.oracle.svm.core.log.Log;\nimport com.oracle.svm.core.thread.JavaVMOperation;\n\n\nJavaVMOperation.enqueueBlockingSafepoint(\"histo\", () -> {\n    ClassHistogramVisitor vis = ClassHistogramVisitor.factory();\n    Heap.getHeap().walkImageHeapObjects(vis);\n    vis.toLogByCount(Log.log(), 0, false);\n});","title":"Print heap histogram from inside binary"},{"location":"/jvm/loom.html","text":"","title":"Project Loom"},{"location":"/jvm/loom.html#project-loom","text":"Fibers and continuations on the JVM\nHomepage | Wiki","title":"Project Loom"},{"location":"/jvm/loom.html#presentations","text":"Project Loom with Ron Pressler and Alan Bateman (youtube)","title":"Presentations"},{"location":"/hosting/index.html","text":"","title":"Hosting"},{"location":"/hosting/index.html#hosting","text":"Hosting Providers Provisioning Kubernetes Tools Cloud Storage Cloud Batch Jobs","title":"Hosting"},{"location":"/hosting/providers.html","text":"","title":"Hosting Providers"},{"location":"/hosting/providers.html#hosting-providers","text":"","title":"Hosting Providers"},{"location":"/hosting/providers.html#benchmarks","text":"www.webhosterwissen.de","title":"Benchmarks"},{"location":"/hosting/providers.html#providers","text":"","title":"Providers"},{"location":"/hosting/providers.html#hetzner","text":"Homepage\nCloud and dedicated servers with datacenters in Germany and Finland.","title":"Hetzner"},{"location":"/hosting/providers.html#netcup","text":"Homepage\nGerman provider with nice price/performance rating. Offers VPS where the CPUs are shared with hourly billing (cloud style) and root servers which are virtualized with monthly billing and dedicated CPU resources.","title":"Netcup"},{"location":"/hosting/providers.html#vultr","text":"Homepage\nCloud servers with SSDs with world wide data centers.","title":"vultr"},{"location":"/hosting/providers.html#exoscale","text":"Homepage\nCloud servers in Switzerland.","title":"Exoscale"},{"location":"/hosting/providers.html#transip","text":"Homepage","title":"TransIp"},{"location":"/hosting/providers.html#buyvm","text":"Homepage\nOffers anycast “for free”, if you got VPSs in every of their three data center locations.","title":"BuyVM"},{"location":"/hosting/provisioning.html","text":"","title":"Provisioning"},{"location":"/hosting/provisioning.html#provisioning","text":"","title":"Provisioning"},{"location":"/hosting/provisioning.html#terraform","text":"Homepage\n“Write, Plan, and Create Infrastructure as Code”\nSupport for many hosting providers and tools.","title":"Terraform"},{"location":"/hosting/provisioning.html#helm","text":"Github\n“Curated applications for Kubernetes”\nA catalogue of “charts”, which are recipes for setting up applications in kubernetes.","title":"Helm"},{"location":"/hosting/provisioning.html#bitnami","text":"Homepage\n“Packaged Applications for Any Platform”\nPre-packaged and supported docker containers for a variety of common software.","title":"bitnami"},{"location":"/hosting/provisioning.html#hobby-kube","text":"Homepage\nA guide to provisioning a kubernetes cluster using terraform for a big variety of hosting platforms.","title":"hobby-kube"},{"location":"/hosting/provisioning.html#kubectl-guide","text":"Homepage\nSuperficially, just the reference documentation for kubectl but beyond that shares lots of wisdom of how to structure kubernetes setups (using kustomization.yaml).","title":"kubectl guide"},{"location":"/hosting/kubernetes.html","text":"","title":"Kubernetes Tools"},{"location":"/hosting/kubernetes.html#kubernetes-tools","text":"","title":"Kubernetes Tools"},{"location":"/hosting/kubernetes.html#network-driver","text":"","title":"Network driver"},{"location":"/hosting/kubernetes.html#calico","text":"","title":"Calico"},{"location":"/hosting/kubernetes.html#storage","text":"","title":"Storage"},{"location":"/hosting/kubernetes.html#rook","text":"Homepage\nA “cloud-native storage orchestrator”. It can provide ceph-based storage directly from kubernetes node attached storage.","title":"Rook"},{"location":"/hosting/cloud-storage.html","text":"","title":"Cloud Storage"},{"location":"/hosting/cloud-storage.html#cloud-storage","text":"","title":"Cloud Storage"},{"location":"/hosting/cloud-storage.html#s3-compatible","text":"","title":"S3 Compatible"},{"location":"/hosting/cloud-storage.html#comparison","text":"Cloud Storage Comparison How Cheap Can Cloud Storage Be","title":"Comparison"},{"location":"/hosting/cloud-storage.html#backblaze-b2","text":"Backblaze B2\n0.005 $/GB/Month 0.01 $/GB out","title":"Backblaze B2"},{"location":"/hosting/cloud-storage.html#wasabi","text":"Wasabi\n$.0059 $/GB/Month No egress cost","title":"Wasabi"},{"location":"/hosting/cloud-batch-jobs.html","text":"","title":"Cloud Batch Jobs"},{"location":"/hosting/cloud-batch-jobs.html#cloud-batch-jobs","text":"Sometimes you just need more compute resources to get some jobs done and just need the compute power to get the job done. For these cases, it would be nice if there would be some cloud infrastructure to easily offload and run those tasks.\nBatch jobs are usually stateless, compute-heavy and often computed on some payload or input file.\nExample batch jobs:\nmedia files analysis (e.g. calculating fingerprints to find similar images in your photo collection) transcoding of media files regular data analysis based e.g. on big CSV files machine learning tasks any kind cron-job (though they are often not CPU-bound so you can get those usually done)\nOften batch jobs are structured like this:\ntype of batch job (“extract video key frames”, “downsize image”) parameters of the batch job (“target image size”, “scaling algorithm”) parameters of the deployment (required amount of memory and CPU / GPU) payload (e.g. file hash / location) output file hash / location\nFunctionality of batch jobs would be represented by a docker image. Input data would often be most usefully represented as an identifier like a URI or a hash if data is content-addressable.\nPotential features:\nautomatic provisioning of resources - no machine setup required, just an API to deploy a load autoscaling - you define resource limits but spinning up nodes etc based on load is automatic automatic data handling - often several jobs need to be run on the same data or output data is to be processed further in another step, for that use case, data should be kept next to the compute resources, e.g. in form of a content-addressable cache data encryption - data should be encrypted in-flight and at rest log handling - logs per job should be accessible\nA batch job often also accesses a DB for input data, these kind of jobs need access to internal infrastructure and also often offload processing load to the DB so they are not easily moved into the cloud if other part of the infrastructure is not already in the cloud as well.\nThe current term for these kinds of services seems to be “serverless container platform” in its generic form.\nFollowing are some current option. Docker-based deployment and autoscaling should work fine. Currently, data management is an aspect that the user has to handle on their own, i.e. a batch job needs to download the payload and upload the result caring for aspects as locality and caching, and encryption themselves.","title":"Cloud Batch Jobs"},{"location":"/hosting/cloud-batch-jobs.html#aws-fargate","text":"Homepage\nFrom the FAQ:\nQ: What use cases does AWS Fargate support? AWS Fargate supports all of the common container use cases, for example microservices architecture applications, batch processing, machine learning applications, and migrating on premise applications to the cloud.","title":"AWS fargate"},{"location":"/hosting/cloud-batch-jobs.html#iron-io-ironworker","text":"Homepage","title":"iron.io IronWorker"},{"location":"/hosting/cloud-batch-jobs.html#google-cloud-run","text":"Homepage","title":"Google Cloud Run"},{"location":"/hosting/cloud-batch-jobs.html#azure-equivalent","text":"To-be-researched","title":"Azure Equivalent"},{"location":"/ml/index.html","text":"","title":"Machine Learning"},{"location":"/ml/index.html#machine-learning","text":"Face Recognition","title":"Machine Learning"},{"location":"/ml/face-recognition.html","text":"","title":"Face Recognition"},{"location":"/ml/face-recognition.html#face-recognition","text":"","title":"Face Recognition"},{"location":"/ml/face-recognition.html#face-recognition","text":"Github\nSeems to be very popular (16000+ stars). Simple to use, just create a single folder with photos which show a single person. Then also point it to another folder with photos and it will detect and recognize persons in there.\nCommand line usage has the problem that only giving a single reference photo might be worse than giving a corpus of reference images. (But that should be easy build on top of face_recognition/dlib)\nTurns out it is only a super simple (200 lines) python wrapper over dlib’s “state-of-the-art face recognition” python API. dlib only has C++ and python APIs.","title":"face_recognition"},{"location":"/ml/face-recognition.html#dlib","text":"Homepage | Github\nC++ and python APIs for all kinds of mathematical and ML tasks.\nIt seems no effort is made of providing a Java binding any time soon. Instead, the developers point to SWIG for creating bindings semi-automatically (which means writing simple enough C++ code to be auto-converted into Java bindings).","title":"dlib"},{"location":"/ml/face-recognition.html#fawkes","text":"Homepage | Paper | Github\nAdds barely visibile pertubations to faces to prevent face recognition to work correctly.","title":"Fawkes"},{"location":"/documentation.html","text":"","title":"Documentation Tools"},{"location":"/documentation.html#documentation-tools","text":"","title":"Documentation Tools"},{"location":"/documentation.html#paradox","text":"Homepage | Github\nMarkdown-based software documentation tool. Most easily used from sbt. (Also used for this site)","title":"Paradox"},{"location":"/documentation.html#paradox-material-theme","text":"Homepage | Github\nA nice paradox theme based on MkDocs Material which itself is based on Material Designhttps://material.io/guidelines/material-design/).","title":"Paradox Material Theme"},{"location":"/documentation.html#pandoc","text":"Homepage\nPandoc can convert all kinds of hypertexts into each other.\nIf you start from scratch and want to support all kinds of output formats, it’s probably easiest to start from markdown.","title":"Pandoc"},{"location":"/various/index.html","text":"","title":"Various"},{"location":"/various/index.html#various","text":"Low-Level Programming Terminal Programming","title":"Various"},{"location":"/various/low-level.html","text":"","title":"Low-Level Programming"},{"location":"/various/low-level.html#low-level-programming","text":"","title":"Low-Level Programming"},{"location":"/various/low-level.html#intel-64-and-ia-32-architectures-software-developer-s-manual","text":"PDF","title":"Intel® 64 and IA-32 Architectures Software Developer’s Manual"},{"location":"/various/low-level.html#cycles-per-instructions-for-different-cpu-microarchitectures","text":"PDF","title":"Cycles Per Instructions for different CPU microarchitectures"},{"location":"/various/terminal.html","text":"","title":"Terminal Programming"},{"location":"/various/terminal.html#terminal-programming","text":"","title":"Terminal Programming"},{"location":"/various/terminal.html#terminal-guide","text":"Homepage | Github","title":"Terminal Guide"}]}